
## 定义
最优化问题是在一定的约束条件下求一个函数的最大（小）值。

## 导数与梯度
- 在极值点处，函数的导数必定为0。求函数的极值就是找函数导数等于0的点。
- **梯度**：对于多元函数，梯度是各个自变量偏导数形成的向量，梯度为0的点是函数取极值的必要条件。
一个优化问题 全局最小值点 $x^*$ 是指对于可行域里所有的 $x$ ，有：
$$ f(x^*) \leq f(x), \quad \forall x \text{ in the domain} $$

- 局部最小值
局部最小值点 $x^\#$ 的定义是：对于 $x^\#$，存在一个 $\delta$ 邻域（$||x - x^\#|| \leq \delta$），使得其中的所有 $x$，有：
$$ f(x^\#) \leq f(x), \quad \forall x \text{ such that } ||x - x^\#|| \leq \delta $$
- 一般而言，我们的目标是找到全局最小值。然而，有些复杂的目标函数有多个局部最小值点。这就需要比较这些点处的目标函数值来确定全局最小值。

- 一般求数值解，使用迭代法，从一个初始点$x_0$开始，基于某种规则，从$x_k$移动到下一个点$x_(k+1)$,构造这样一个数列，直到找到使得梯度为0的点为止。$\lim_{k \rightarrow + \infty}\nabla f(x_k)=0)$
- 迭代公式：一般会用到一阶导数信息（梯度），或者二阶导数信息（ Hessian矩阵）。迭代公式的数学定义：$x_{k+1}=h(x_k)$

## 梯度下降法
- **基本思想**：从一个初始点出发，逐步沿着函数的梯度反方向（下降最快的方向）移动，直到找到使得梯度为0的点。
- **迭代公式**：考虑到一元函数的Taylor展开公式，用梯度信息设计迭代公式，忽略二次及更高项。
- **公式**：
  $$
  x_{\text{new}} = x_{\text{old}} - t \cdot \nabla f(x), \quad \text{其中} \ t>0 \ \text{为步长}
  $$
### 最速下降法
- Steepest Descent
	- 在每次迭代时寻找最合适的步长来最小化目标函数。
	- $t^* = \arg\min \phi(t)$
	- $\text{\ \ \ s.t. } \phi(t) = f(\mathbf{x}_k - t \cdot \nabla f(\mathbf{x}_k))$
	- 在第$k$次迭代时的步长，寻找最合适的$t^*$来最小化函数$f(\mathbf{x})$
	- 给定第$k$次迭代的最优步长= $t_k$, 则迭代公式如下所示
	- $\mathbf{x}_{k+1} = \mathbf{x}_k - t_k \cdot \nabla f(\mathbf{x}_k)$
	- ![[Pasted image 20231208155404.png]]
### 随机梯度下降法
- Stochastic Gradient Descent SGD
	- 也叫增量梯度下降
		- $$\theta_{t+1} = \theta_t - \alpha \frac{\partial \mathcal{L}(\theta_t; x^{(t)}, y^{(t)})}{\partial \theta}$$
			- **超参数（模型之外的参数）**
				- 学习率 learning rate
					- ![[Pasted image 20231208155737.png]]![[Pasted image 20231208155604.png]]

### 小批量随机梯度下降法
- Mini-batch
	- $$\theta_{t+1} = \theta_t - \alpha \frac{\partial \mathcal{R}(\theta)}{\partial \theta_t}$$
	- $$\theta_{t+1} = \theta_t - \frac{\alpha}{N} \sum_{i=1}^{N} \frac{\partial \mathcal{L}(\theta_t; x^{(i)}, y^{(i)})}{\partial \theta}$$

## 停止准测 Stopping Criteria
- **停止准则**：使用验证集来测试每一次迭代的参数在验证集上是否最优。如果在验证集上的错误率不再下降，则停止迭代。
	- ![[Pasted image 20231208155938.png]]
- **全局最小值与局部最小值**：全局最小值是指在整个可行域中的最小值点。局部最小值是指在某个邻域内的最小值点。

## 鞍点
- **鞍点**：鞍点是指函数在某点的一阶导数为0，但该点既不是局部最小值也不是局部最大值的点。在多元函数中，鞍点处的Hessian矩阵既不是正定也不是负定。
- Hessian矩阵： 二阶导
	- $$H = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \frac{\partial^2 f}{\partial x_n \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}
$$
- 正定 负定 是什么意思
	- **正定矩阵**：如果对于所有非零向量 v，都有 $v^T H v > 0$ 这意味着函数在该点有一个局部最小值。
	- **负定矩阵**：如果对于所有非零向量 v，都有 $v^T H v < 0$ 这意味着函数在该点有一个局部最大值。

## 其他优化方法
- **牛顿法**：使用函数的二阶导数信息。 Newton's method
- **拟牛顿法**：如BFGS，不直接计算二阶导数，而是近似估计。Quasi-Newton  Method
- **共轭梯度法**：不需要存储Hessian矩阵，适用于大规模问题。Conjugate Gradient
- **拉格朗日乘数法**：用于解决带约束的优化问题。

## 凸优化的困难
求解一个一般性的最优化问题的全局极小值是十分困难的，可能存在多个局部最小点，造成计算成本太高，存在多个鞍点的话，则无解
梯度下降、牛顿法都是基于导数的优化算法
	限定条件：凸函数+凸集，这样局部最优解一定是全局最优解
- **目标函数是凸函数，可行域和目标函数定义域是凸集**
	- **凸集**：对于n维空间中的点集，若对集合中的任意两点和任意实数，都有该集合为凸集。
		- ![[Pasted image 20231208162026.png]]
	- **凸函数**：一个函数是凸函数，如果其在任何点处的切线都位于函数的下方。
		- 凸函数数学[[Notes(For AI)]]
	- 凸函数判定方法：一元函数的二阶导数，多元函数的Hessian矩阵为半正定矩阵。

## 机器学习与凸优化
机器学习并不是凸优化
**经验风险最小化**原则很容易导致模型在训练集上错误率很低，但是在未知数据上错误率很高
不是总希望最小，而是不要过拟合。
机器学习需要避免过拟合，要在测试集上表现最优

### 期望风险与经验风险(GPT)
![[Pasted image 20231208163452.png]]
在机器学习和统计学中，**期望风险**（Expected Risk）和**经验风险**（Empirical Risk）是评估学习算法性能的两个重要概念。

#### 期望风险 (Expected Risk)
期望风险是模型在整个数据生成分布上的平均损失，通常被定义为损失函数$ L $相对于数据生成分布$p(x, y)$的期望值。换句话说，它是模型在所有可能的数据上的平均表现。数学上，期望风险$R(f)$可以用以下公式表达：

$$R(f) = \mathbb{E}_{(x,y) \sim p(x,y)} \left[ L(f(x), y) \right]$$

这里，$\mathbb{E}$表示期望操作符，$p(x,y)$表示数据的联合分布，$L$是损失函数，$f(x)$是模型的预测输出，而$y$是真实的标签。

#### 经验风险 (Empirical Risk)
经验风险是模型在有限训练数据上的平均损失，它是期望风险的一个近似，因为我们通常没有办法访问整个数据生成分布。经验风险通常用于训练模型，是损失函数关于训练数据的平均值。数学上，经验风险$R_{D}^{\text{emp}}(\theta)$可以用以下公式表达：

$$R_{D}^{\text{emp}}(\theta) = \frac{1}{N} \sum_{n=1}^{N} L(y^{(n)}, f(x^{(n)}, \theta))$$

在这里，$N$是训练样本的数量，$L$是损失函数，$x^{(n)}$和$y^{(n)}$分别是第$n$个训练样本的特征和标签，$\theta$表示模型参数。

### 期望风险与经验风险的差异
期望风险是理论上最准确的风险度量，它涉及到所有可能的数据，包括我们未能观察到的数据。而经验风险仅考虑训练集中的数据，因此可能受到数据集大小和数据集特性的限制。理想的学习算法应该最小化期望风险，但由于我们不能访问整个数据生成分布，我们通常通过最小化经验风险来近似这个目标。

### 正则化 Regularization
所有“损害"优化的方法都是正则化
- 增加优化约束
	- L1/L2约束
		- L1正则化（Lasso）通过向损失函数添加模型权重的绝对值之和来约束模型参数
			- $$ \text{Cost} + \lambda \sum |w_i| $$
		- L2正则化（Ridge）通过添加权重的平方之和来约束模型参数：
			- $$ \text{Cost} + \lambda \sum w_i^2 $$

在这两种正则化中，$\lambda$是一个控制正则化强度的超参数，$w_i$是模型的权重。
L1正则化倾向于产生稀疏的权重矩阵（许多权重为零），有助于特征选择。
L2正则化则倾向于使权重接近于零但不会完全为零，这有助于减少模型参数的总量，从而减少过拟合的风险。
![[Pasted image 20231208164617.png]]

- 数据增强
	- Data Augmentation
- 干扰优化过程
	- 权重衰减
	- 随机梯度下降
	- 提前停止防止过拟合
