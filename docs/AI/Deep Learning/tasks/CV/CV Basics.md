## Definition
给机器看的能力
[[Classic Models]]
## 主要领域
- 计算机成像学
	- Low-level
	- 图像去噪
	- 图像超分辨率
	- 图像增强
	- 风格变换
- 图像理解
	- 图像分类
	- 目标检测
	- 人脸识别
	- 语义分割
- 三维视觉
- 视频理解
## 三大会议
CVPR
ICCV
ECCV

## 图像分类
根据图像的语义信息将不同类别的图像区分开来，是其他任务的基础
- 图像数据
- 特征提取
	- 减少数据维度
	- 提取或整理出有效的特征以提升后续模型的表现能力
	- 方法
		- bag of words
		- deep learning
		- sliding window
- 分类器

## 物体检测
▪two-stage方法有其固有缺点，即是第一阶段都要进行候选区域提取会消耗很多时间，使目标检测的耗时增加，效率降低。
▪因此在此基础上，研究人员对目标检测方法进行了改进，提出了one-stage方法，可以直接对物体的坐标和类别进行回归而不需要进行显式的提取候选区域的过程。

### Two-stage检测算法
其将检测问题划分为两个阶段，首先产生候选区域（region proposals），然后对候选区域分类（一般还需要对位置精修），这类算法的典型代表是基于region proposal的R-CNN系算法，如R-CNN，Fast R-CNN，Faster R-CNN等


#### 候选区域产生：Selective Search

##### 基本合并算法:
1. 使用 Efficient Graph-Based Image Segmentation 方法初始化最小相似区域 $r_{1}, r_{2}, ..., r_{n}$。
2. 为相似区域度量定义 $s$。
3. 计算两两相邻区域之间的相似度，将其添加到相似度集合 $S$ 中。
4. 从 $S$ 中找到最相似的两个区域 $r_{i}$ 和 $r_{j}$，将其合并为一个新区域，从 $S$ 中移除与 $r_{i}$ 和 $r_{j}$ 相关的相似度，计算新区域与相邻区域之间的新相似度并添加到 $S$ 中。重复此过程直到只剩下一个区域为止。
5. 记录每个区域的 Bounding Boxes，这个过程会生成大量可能的对象候选区域。

##### 相似度计算：相似度计算方法有四种
1. 颜色 (color) 相似度：计算颜色直方图距离，计算颜色相似度。
2. 纹理 (texture) 相似度：计算的纹理采用 SIFT-Like 特征。
3. 大小 (size) 相似度：计算的大小是指区域中包含像素的个数，使用大小的相似度计算，主要为了保留小的区域特性。
4. 合适 (fit) 相似度：计算主要是为了避免两个重叠区域合并为 “大块”，导致误合并有用的区域的 Bounding Box 小块，其中合适度较高。

最后区域的相似度计算为所有这些属性的加权和：$S = a * s(color) + b * s(texture) + c * s(size) + d * s(fit)$
![[Pasted image 20231209150536.png]]


#### R-CNN
▪R-CNN是基于region proposal方法的目标检测算法系列开山之作，其先进行区域搜索，然后再对候选区域进行分类
▪候选区域（Region Proposal）：基于Selective Search，利用图像中的纹理、边缘、颜色等信息，保证在选取较少窗口(几千甚至几百）的情况下保持较高的召回率（Recall）
▪总体来看，R-CNN是非常直观的，就是把检测问题转化为了分类问题，并且采用了CNN模型进行分类，但是效果却很好
▪2012 PASCAL VOC数据集的mAP为62.4%（比第二名高出22%）
▪在2013 ImageNet上的mAP为31.4%（比第二名高出7.1%）

R-CNN模型的训练是**多管道**的，CNN模型首先使用ImageNet中的图像分类竞赛数据集进行预训练。然后在检测数据集上对CNN模型进行finetuning，其中那些与真实框的IoU大于0.5的候选区域作为正样本，剩余的候选区域是负样本（背景）
**多管道（Multi-stage pipeline）"在R-CNN模型训练中的意思是训练过程包含多个连续的步骤或阶段。每个步骤或阶段都使用不同的数据集或不同的训练目标。**

▪R-CNN缺点：
(1) 训练分为多个阶段，微调网络+训练SVM+训练边框回归器
(2) 训练耗时，占用磁盘空间大：5000张图像产生几百G的特征文件
(3) 速度慢: 使用GPU, VGG16模型处理一张图像需要47s
(4) 测试速度慢：每个候选区域需要运行整个前向CNN计算
(5) SVM和bounding box回归是事后操作：在SVM和回归过程中CNN特征没有被学习更新
(6) 输入图片的大小必须要固定（224x224、227x227等）
### SPPNet
▪何恺明：SPPNet (Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition) 2014年
▪R-CNN对图像提完Region Proposal（2000个左右）之后将每个Proposal当成一张图像进行后续处理(CNN提特征+SVM分类)，实际上对一张图像进行了2000次提特征和分类的过程
▪完全可以对图像**只提取一次卷积层特征，然后只需要将Region Proposal在原图的位置映射到卷积层特征图上**，这样对于一张图像我们只需要提一次卷积层特征，然后将每个Region Proposal的卷积层特征输入到全连接层做后续操作

### One-stage检测算法
其不需要region proposal阶段，直接产生物体的类别概率和位置坐标值，比较典型的算法如YOLO、SSD等

#### YOLO
*You Only Look Once* 速度快 定位识别在同一个网络中完成 基于整张图片预测bounding boxes

2016年提出一个全新的方法，一次性把一整张图片用到一个神经网络中去。网络把图片分成不同的区域，然后给出每个区域的边框预测和概率，并依据概率大小对所有边框分配权重。最后，设置阈值，只输出得分（概率值）超过阈值的检测结果。主要采用了AlexNet

▪YOLO的目标检测的流程：
▪ 给个一个输入图像，resize图像，将图像划分网格 S\*S个grid cells
▪对于每个网格，负责一个物体，都预测2个边框（包括每个边框是目标的置信度以及每个边框区域在多个类别上的概率）![[Pasted image 20231209151722.png]]
▪保留confidence score大于0.25的bounding boxes
▪最后用Non-maximum suppression (NMS)
	![[Pasted image 20231209151637.png]]

> NMS
> 非极大值抑制（NMS）是一种在目标检测中用来清理重叠边界框的算法，它只保留最有可能包含目标的边界框。在YOLO这样的目标检测模型中，NMS通过以下步骤工作：
>	1. 对所有预测的边界框按置信度排序。
>	2. 选择置信度最高的边界框，移除所有与它重叠度**较高**的其他框。
>	3. 重复第二步，直到所有框都被处理。
>	4. 这个过程确保每个目标只有一个边界框被最终选定。
